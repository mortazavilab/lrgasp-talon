import pdb
import pandas as pd
from src.utils.io import read_data_matrix

configfile: "configs/config.yaml"

tools = ['talon']


def _get_row(encode_id):
    df = read_data_matrix(config['encode']['data_matrix'])
    return df.loc[encode_id]


def fasta(wildcards):
    wildcards = dict(wildcards)
    if 'specie' in wildcards:
        return config['lrgasp']['reference'][wildcards['specie']]['fasta']
    elif 'encode_id' in wildcards:
        row = _get_row(wildcards['encode_id'])
        return config['lrgasp']['reference'][row['species']]['fasta']
    else:
        raise ValueError('fasta cannot be determined from wildcards.')


def gtf(wildcards):
    wildcards = dict(wildcards)
    if 'specie' in wildcards:
        return config['lrgasp']['reference'][wildcards['specie']]['gtf']
    elif 'encode_id' in wildcards:
        row = _get_row(wildcards['encode_id'])
        return config['lrgasp']['reference'][row['species']]['gtf']
    else:
        raise ValueError('gtf cannot be determined from wildcards.')


# def fastq_files(wildcards):
#     df = read_data_matrix(config['encode']['data_matrix'], wildcards)
#     return [
#         f'{config["encode"]["fastq_dir"]}/{row["species"]}_{row["sample"]}_{row["library_prep"]}_{row["platform"]}_{row["replicate"]}_{row["file_acc"]}.fastq'
#         for i, row in df.iterrows()
#     ]


# def fastq_paired(wildcards):
#     df = read_data_matrix(config['encode']['data_matrix'], wildcards)
#     return [
#         f'{config["encode"]["fastq_dir"]}/{row["species"]}_{row["sample"]}_{row["library_prep"]}_{row["platform"]}_{row["replicate"]}_{row["paired_acc"]}.fastq'
#         for i, row in df.iterrows()
#     ]


# def expand_encode(path, wildcards):
#     df = read_data_matrix(config['encode']['data_matrix'], wildcards)
#     return [
#         path.format(specie=row['species'], sample=row['sample'],
#                     library_prep=row['library_prep'], platform=row['platform'],
#                     rep=row['replicate'], acc=row['file_acc'])
#         for i, row in df.iterrows()
#     ]


include: "./rules/download.smk"
include: "./rules/align.smk"
# include: "./rules/stringtie.smk"
include: "./rules/transcriptclean.smk"
include: "./rules/talon.smk"
include: "./rules/benchmark.smk"


# df = read_data_matrix(config['encode']['data_matrix'])
# df = df[
#     (df['species'] == 'human') &
#     (df['sample'] == 'H1mix') &
#     # (df['library_prep'] == 'cDNA') &
#     (df['platform'] == 'ONT') &
#     (df['file_type'] == 'fastq')
# ]

# config['transcriptclean']['sam']
# method=['long', 'short']
# ENCFF288PBL
rule all:
    input:
        expand(
            rules.benchmark_task1.output,
            tool=['talon'],
            specie=['mouse'],
            sample=['ES'],
            library_prep=['CapTrap', 'cDNA'],
            platform=['PacBio'],
            method=['long', 'short']
        ),
        expand(
            rules.benchmark_task1.output,
            tool=['talon'],
            specie=['mouse'],
            sample=['ES'],
            library_prep=['cDNA', 'dRNA'],
            platform=['ONT'],
            method=['long', 'short']
        )

        # dynamic(expand(config['transcriptclean']['sam_clean_batch'],
        #                encode_id='ENCFF232YSU', method='long', batch_id='{batch_id}'))

        # expand(
        #     rules.benchmark_task1.output,
        #     tool=['talon'],
        #     specie=['human'],
        #     sample=['WTC11', 'H1mix'],
        #     library_prep=['cDNA', 'CapTrap'],
        #     platform=['PacBio'],
        #     method=['long', 'short']
        # ),
        # expand(
        #     rules.benchmark_task1.output,
        #     tool=['talon'],
        #     specie=['human'],
        #     sample=['WTC11', 'H1mix'],
        #     library_prep=['cDNA', 'dRNA'],
        #     platform=['ONT'],
        #     method=['long', 'short']
        # ),
        # expand(
        #     rules.benchmark_task2.output,
        #     tool=['talon'],
        #     specie=['human'],
        #     sample=['WTC11', 'H1mix'],
        #     library_prep=['cDNA', 'CapTrap'],
        #     platform=['PacBio'],
        #     method=['long', 'short']
        # ),
        # expand(
        #     rules.benchmark_task2.output,
        #     tool=['talon'],
        #     specie=['human'],
        #     sample=['WTC11', 'H1mix'],
        #     library_prep=['cDNA', 'dRNA'],
        #     platform=['ONT'],
        #     method=['long', 'short']
        # ),

        # mouse
        # expand(
        #     rules.benchmark_task1.output,
        #     tool=['talon'],
        #     specie=['mouse'],
        #     sample=['ES'],
        #     library_prep=['cDNA', 'dRNA'],
        #     platform=['ONT'],
        #     method=['long', 'short']
        # ),
        # expand(
        #     rules.benchmark_task2.output,
        #     tool=['talon'],
        #     specie=['mouse'],
        #     sample=['ES'],
        #     library_prep=['cDNA', 'CapTrap'],
        #     platform=['PacBio'],
        #     method=['long', 'short']
        # ),
        # expand(
        #     rules.benchmark_task2.output,
        #     tool=['talon'],
        #     specie=['mouse'],
        #     sample=['ES'],
        #     library_prep=['cDNA', 'dRNA'],
        #     platform=['ONT'],
        #     method=['long', 'short']
        # )
        #
        # dynamic(expand(config['transcriptclean']['sam_clean_batch'],
        #                encode_id='ENCFF961HLO', method='long', batch_id='{batch_id}'))
